# YOLOv5检测界面的简单实现

## 写在前面

界面是在*ultralytics*的

[yolov5]: https://github.com/ultralytics/yolov5

基础上建立的，界面使用*pyqt5*实现，内容较简单，娱乐而已。

**功能：**

1. 模型选择
2. 本地文件选择
3. 开关摄像头
4. 运行/终止
5. 统计检测结果

存在的一个小问题，切换模型或者文件过于频繁，可能会卡住，重启一下即可，问题不大。

![新建 Microsoft Visio 绘图](D:\project\deeplearning\project\pytorch\objectdection\yolov5-master\笔记\新建 Microsoft Visio 绘图.jpg)

默认模型为*yolov5s.pt*，默认输入文件为电脑摄像头视频

摄像头检测画面：

![无标题](D:\project\deeplearning\project\pytorch\objectdection\yolov5-master\笔记\无标题.jpg)

本地视频检测画面：

![20210927_141438_Trim 00_00_00-00_00_30~1](D:\FFOutput\20210927_141438_Trim 00_00_00-00_00_30~1.gif)

![无标题2](D:\project\deeplearning\project\pytorch\objectdection\yolov5-master\笔记\无标题2.jpg)

图片检测画面：

![image-20210927133525899](C:\Users\11602\AppData\Roaming\Typora\typora-user-images\image-20210927133525899.png)

## 要做的事

**一.** 将*yolov5*的*utils/datasets.py*中*LoadWebcam*类中*__next__*的返回值改为

```python
return img_path, img, img0, self.cap #（位置在270行上下）。
```

**二.** 为了避免中文路径报错（路径不包含中文可以忽略这一步），将*utils/datasets.py*中*LoadImages*类中的

```python
img0 = cv2.imread(path)	#（位置在212行上下）。
```

改为

```
img0 = cv2.imdecode(np.fromfile(path, dtype=np.uint8), 1)
```

**三.** 在*yolov5-master*根目录下创建*main_ui.py、yolo_win.py*和*icon*文件夹（存放图标）。

运行*yolo_win.py*即可开启检测界面。

代码及图标压缩包链接：

链接：https://pan.baidu.com/s/1haHsQ0cE7NBixlPqUVW_iw 
提取码：6666

或者复制以下的代码

ui代码--main_ui.py

```python
# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file '.\newviewer9262.ui'
#
# Created by: PyQt5 UI code generator 5.15.2
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets


class Ui_MainWindow(object):
    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(1036, 600)
        icon = QtGui.QIcon()
        icon.addPixmap(QtGui.QPixmap("./icon/图片1.png"), QtGui.QIcon.Normal, QtGui.QIcon.Off)
        MainWindow.setWindowIcon(icon)
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")
        self.verticalLayout = QtWidgets.QVBoxLayout(self.centralwidget)
        self.verticalLayout.setObjectName("verticalLayout")
        self.groupBox = QtWidgets.QGroupBox(self.centralwidget)
        self.groupBox.setTitle("")
        self.groupBox.setObjectName("groupBox")
        self.verticalLayout_4 = QtWidgets.QVBoxLayout(self.groupBox)
        self.verticalLayout_4.setObjectName("verticalLayout_4")
        self.horizontalLayout_3 = QtWidgets.QHBoxLayout()
        self.horizontalLayout_3.setSpacing(4)
        self.horizontalLayout_3.setObjectName("horizontalLayout_3")
        self.verticalLayout_3 = QtWidgets.QVBoxLayout()
        self.verticalLayout_3.setObjectName("verticalLayout_3")
        self.horizontalLayout = QtWidgets.QHBoxLayout()
        self.horizontalLayout.setSpacing(3)
        self.horizontalLayout.setObjectName("horizontalLayout")
        self.label_2 = QtWidgets.QLabel(self.groupBox)
        self.label_2.setEnabled(False)
        font = QtGui.QFont()
        font.setFamily("Agency FB")
        font.setPointSize(14)
        self.label_2.setFont(font)
        self.label_2.setScaledContents(True)
        self.label_2.setAlignment(QtCore.Qt.AlignCenter)
        self.label_2.setObjectName("label_2")
        self.horizontalLayout.addWidget(self.label_2, 0, QtCore.Qt.AlignHCenter)
        self.label = QtWidgets.QLabel(self.groupBox)
        self.label.setEnabled(False)
        font = QtGui.QFont()
        font.setFamily("Agency FB")
        font.setPointSize(14)
        self.label.setFont(font)
        self.label.setScaledContents(True)
        self.label.setAlignment(QtCore.Qt.AlignCenter)
        self.label.setObjectName("label")
        self.horizontalLayout.addWidget(self.label)
        self.verticalLayout_3.addLayout(self.horizontalLayout)
        self.horizontalLayout_2 = QtWidgets.QHBoxLayout()
        self.horizontalLayout_2.setObjectName("horizontalLayout_2")
        self.label_raw = QtWidgets.QLabel(self.groupBox)
        self.label_raw.setAutoFillBackground(False)
        self.label_raw.setStyleSheet("background-color: rgb(221, 221, 221);")
        self.label_raw.setText("")
        self.label_raw.setScaledContents(False)
        self.label_raw.setAlignment(QtCore.Qt.AlignCenter)
        self.label_raw.setObjectName("label_raw")
        self.horizontalLayout_2.addWidget(self.label_raw)
        self.label_result = QtWidgets.QLabel(self.groupBox)
        self.label_result.setStyleSheet("background-color: rgb(221, 221, 221);")
        self.label_result.setFrameShape(QtWidgets.QFrame.NoFrame)
        self.label_result.setFrameShadow(QtWidgets.QFrame.Sunken)
        self.label_result.setText("")
        self.label_result.setScaledContents(False)
        self.label_result.setAlignment(QtCore.Qt.AlignCenter)
        self.label_result.setObjectName("label_result")
        self.horizontalLayout_2.addWidget(self.label_result)
        self.verticalLayout_3.addLayout(self.horizontalLayout_2)
        self.verticalLayout_3.setStretch(1, 10)
        self.horizontalLayout_3.addLayout(self.verticalLayout_3)
        self.line = QtWidgets.QFrame(self.groupBox)
        self.line.setFrameShape(QtWidgets.QFrame.VLine)
        self.line.setFrameShadow(QtWidgets.QFrame.Sunken)
        self.line.setObjectName("line")
        self.horizontalLayout_3.addWidget(self.line)
        self.verticalLayout_2 = QtWidgets.QVBoxLayout()
        self.verticalLayout_2.setObjectName("verticalLayout_2")
        self.statistic = QtWidgets.QPushButton(self.groupBox)
        self.statistic.setEnabled(False)
        font = QtGui.QFont()
        font.setFamily("Agency FB")
        font.setPointSize(11)
        font.setStyleStrategy(QtGui.QFont.PreferDefault)
        self.statistic.setFont(font)
        self.statistic.setAcceptDrops(False)
        self.statistic.setAutoFillBackground(False)
        self.statistic.setStyleSheet("background:transparent")
        self.statistic.setObjectName("statistic")
        self.verticalLayout_2.addWidget(self.statistic, 0, QtCore.Qt.AlignHCenter|QtCore.Qt.AlignVCenter)
        self.listWidget = QtWidgets.QListWidget(self.groupBox)
        font = QtGui.QFont()
        font.setPointSize(9)
        self.listWidget.setFont(font)
        self.listWidget.setStyleSheet("background:transparent")
        self.listWidget.setFrameShadow(QtWidgets.QFrame.Plain)
        self.listWidget.setProperty("showDropIndicator", True)
        self.listWidget.setObjectName("listWidget")
        self.verticalLayout_2.addWidget(self.listWidget)
        self.horizontalLayout_3.addLayout(self.verticalLayout_2)
        self.horizontalLayout_3.setStretch(0, 9)
        self.horizontalLayout_3.setStretch(2, 1)
        self.verticalLayout_4.addLayout(self.horizontalLayout_3)
        self.verticalLayout.addWidget(self.groupBox)
        MainWindow.setCentralWidget(self.centralwidget)
        self.statusbar = QtWidgets.QStatusBar(MainWindow)
        self.statusbar.setObjectName("statusbar")
        MainWindow.setStatusBar(self.statusbar)
        self.toolBar = QtWidgets.QToolBar(MainWindow)
        self.toolBar.setObjectName("toolBar")
        MainWindow.addToolBar(QtCore.Qt.TopToolBarArea, self.toolBar)
        self.SelModel = QtWidgets.QAction(MainWindow)
        icon1 = QtGui.QIcon()
        icon1.addPixmap(QtGui.QPixmap("./icon/数据探索.png"), QtGui.QIcon.Normal, QtGui.QIcon.On)
        self.SelModel.setIcon(icon1)
        self.SelModel.setObjectName("SelModel")
        self.SelFile = QtWidgets.QAction(MainWindow)
        icon2 = QtGui.QIcon()
        icon2.addPixmap(QtGui.QPixmap("./icon/打开.png"), QtGui.QIcon.Normal, QtGui.QIcon.On)
        self.SelFile.setIcon(icon2)
        self.SelFile.setObjectName("SelFile")
        self.RunProgram = QtWidgets.QAction(MainWindow)
        self.RunProgram.setCheckable(True)
        self.RunProgram.setChecked(False)
        self.RunProgram.setEnabled(True)
        icon3 = QtGui.QIcon()
        icon3.addPixmap(QtGui.QPixmap("./icon/停止.png"), QtGui.QIcon.Normal, QtGui.QIcon.On)
        icon3.addPixmap(QtGui.QPixmap("./icon/赞停.png"), QtGui.QIcon.Active, QtGui.QIcon.Off)
        icon3.addPixmap(QtGui.QPixmap("./icon/停止.png"), QtGui.QIcon.Active, QtGui.QIcon.On)
        self.RunProgram.setIcon(icon3)
        self.RunProgram.setObjectName("RunProgram")
        self.cam_switch = QtWidgets.QAction(MainWindow)
        self.cam_switch.setCheckable(True)
        icon4 = QtGui.QIcon()
        icon4.addPixmap(QtGui.QPixmap("./icon/摄像头开.png"), QtGui.QIcon.Normal, QtGui.QIcon.Off)
        icon4.addPixmap(QtGui.QPixmap("./icon/摄像头关.png"), QtGui.QIcon.Normal, QtGui.QIcon.On)
        self.cam_switch.setIcon(icon4)
        self.cam_switch.setObjectName("cam_switch")
        self.Exit = QtWidgets.QAction(MainWindow)
        self.Exit.setObjectName("Exit")
        self.toolBar.addAction(self.SelModel)
        self.toolBar.addAction(self.SelFile)
        self.toolBar.addAction(self.cam_switch)
        self.toolBar.addAction(self.RunProgram)

        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)

    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "YOLOV5检测界面"))
        self.label_2.setText(_translate("MainWindow", "输入数据"))
        self.label.setText(_translate("MainWindow", "检测结果"))
        self.statistic.setText(_translate("MainWindow", "统计"))
        self.toolBar.setWindowTitle(_translate("MainWindow", "toolBar"))
        self.SelModel.setText(_translate("MainWindow", "选择模型"))
        self.SelModel.setToolTip(_translate("MainWindow", "选择模型"))
        self.SelFile.setText(_translate("MainWindow", "选择文件"))
        self.SelFile.setToolTip(_translate("MainWindow", "选择文件"))
        self.RunProgram.setText(_translate("MainWindow", "执行程序"))
        self.RunProgram.setToolTip(_translate("MainWindow", "执行程序"))
        self.cam_switch.setText(_translate("MainWindow", "摄像头开关"))
        self.cam_switch.setToolTip(_translate("MainWindow", "摄像头开关"))
        self.Exit.setText(_translate("MainWindow", "退出"))

```

主函数代码--yolo_win.py

```python
# -*- coding: utf-8 -*-
from PyQt5.QtWidgets import QApplication, QMainWindow, QFileDialog, QWidget
from main_ui import Ui_MainWindow
from PyQt5.QtCore import pyqtSignal, QThread, QTimer
from PyQt5.QtGui import QImage, QPixmap
import sys
import time
from pathlib import Path
import numpy as np
import cv2
import torch
import torch.backends.cudnn as cudnn
import os
FILE = Path(__file__).absolute()
sys.path.append(FILE.parents[0].as_posix())  # add yolov5/ to path

from models.experimental import attempt_load
from utils.datasets import LoadImages, LoadWebcam
# LoadWebcam 的最后一个返回值改为 self.cap
from utils.general import check_img_size, check_requirements, check_imshow, colorstr, non_max_suppression, \
    apply_classifier, scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path, save_one_box
from utils.plots import colors, plot_one_box
from utils.torch_utils import select_device, load_classifier, time_sync


class DetThread(QThread):
    send_img = pyqtSignal(np.ndarray)
    send_raw = pyqtSignal(np.ndarray)
    send_statistic = pyqtSignal(dict)
    weights = './yolov5s.pt'
    source = '0'

    def __init__(self):
        super(DetThread, self).__init__()

    @torch.no_grad()
    def run(self,
            imgsz=640,  # inference size (pixels)
            conf_thres=0.25,  # confidence threshold
            iou_thres=0.45,  # NMS IOU threshold
            max_det=1000,  # maximum detections per image
            device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu
            view_img=True,  # show results
            save_txt=False,  # save results to *.txt
            save_conf=False,  # save confidences in --save-txt labels
            save_crop=False,  # save cropped prediction boxes
            nosave=False,  # do not save images/videos
            classes=None,  # filter by class: --class 0, or --class 0 2 3
            agnostic_nms=False,  # class-agnostic NMS
            augment=False,  # augmented inference
            visualize=False,  # visualize features
            update=False,  # update all models
            project='runs/detect',  # save results to project/name
            name='exp',  # save results to project/name
            exist_ok=False,  # existing project/name ok, do not increment
            line_thickness=3,  # bounding box thickness (pixels)
            hide_labels=False,  # hide labels
            hide_conf=False,  # hide confidences
            half=False,  # use FP16 half-precision inference
            ):

        # Initialize
        device = select_device(device)
        half &= device.type != 'cpu'  # half precision only supported on CUDA

        # Load model
        model = attempt_load(self.weights, map_location=device)  # load FP32 model
        num_params = 0
        for param in model.parameters():
            num_params += param.numel()
        stride = int(model.stride.max())  # model stride
        imgsz = check_img_size(imgsz, s=stride)  # check image size
        names = model.module.names if hasattr(model, 'module') else model.names  # get class names
        if half:
            model.half()  # to FP16

        # Dataloader
        if self.source.isnumeric():
            view_img = check_imshow()
            cudnn.benchmark = True  # set True to speed up constant image size inference
            dataset = LoadWebcam(self.source, img_size=imgsz, stride=stride)
            bs = len(dataset)  # batch_size
        else:
            dataset = LoadImages(self.source, img_size=imgsz, stride=stride)

        # Run inference
        if device.type != 'cpu':
            model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once
        for path, img, im0s, self.vid_cap in dataset:
            statistic_dic = {name: 0 for name in names}
            img = torch.from_numpy(img).to(device)
            img = img.half() if half else img.float()  # uint8 to fp16/32
            img /= 255.0  # 0 - 255 to 0.0 - 1.0
            if img.ndimension() == 3:
                img = img.unsqueeze(0)

            pred = model(img, augment=augment)[0]

            # Apply NMS
            pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)
            # Process detections
            for i, det in enumerate(pred):  # detections per image
                im0 = im0s.copy()

                if len(det):
                    # Rescale boxes from img_size to im0 size
                    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()

                    # Write results
                    for *xyxy, conf, cls in reversed(det):
                        c = int(cls)  # integer class
                        statistic_dic[names[c]] += 1
                        label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')
                        plot_one_box(xyxy, im0, label=label, color=colors(c, True), line_thickness=line_thickness)

            time.sleep(1/40)
            # print(type(im0s))
            self.send_img.emit(im0)
            self.send_raw.emit(im0s if isinstance(im0s, np.ndarray) else im0s[0])
            self.send_statistic.emit(statistic_dic)


class MainWindow(QMainWindow, Ui_MainWindow):
    def __init__(self, parent=None):
        super(MainWindow, self).__init__(parent)
        self.setupUi(self)
        self.model = './yolov5s.pt'
        self.det_thread = DetThread()
        self.det_thread.source = '0'
        self.det_thread.send_img.connect(lambda x: self.show_image(x, self.label_result))
        self.det_thread.send_raw.connect(lambda x: self.show_image(x, self.label_raw))
        self.det_thread.send_statistic.connect(self.show_statistic)
        # self.RunProgram.triggered.connect(lambda: self.det_thread.start())
        self.RunProgram.triggered.connect(self.term_or_con)
        self.SelFile.triggered.connect(self.open_file)
        self.SelModel.triggered.connect(self.open_model)
        self.status_bar_init()
        self.cam_switch.triggered.connect(self.camera)

    def status_bar_init(self):
        self.statusbar.showMessage('界面已准备')

    def open_file(self):
        source = QFileDialog.getOpenFileName(self, '选取视频或图片', os.getcwd(), "Pic File(*.mp4 *.mkv *.avi *.flv "
                                                                           "*.jpg *.png)")
        if source[0]:
            self.det_thread.source = source[0]
        self.statusbar.showMessage('加载文件：{}'.format(os.path.basename(self.det_thread.source)
                                                    if os.path.basename(self.det_thread.source) != '0'
                                                    else '摄像头设备'))

    def term_or_con(self):
        if self.RunProgram.isChecked():
            self.det_thread.start()
            self.statusbar.showMessage('正在检测 >> 模型：{}，文件：{}'.
                                       format(os.path.basename(self.det_thread.weights),
                                              os.path.basename(self.det_thread.source)
                                                               if os.path.basename(self.det_thread.source) != '0'
                                                               else '摄像头设备'))
        else:
            self.det_thread.terminate()
            if hasattr(self.det_thread, 'vid_cap'):
                if self.det_thread.vid_cap:
                    self.det_thread.vid_cap.release()
            self.statusbar.showMessage('结束检测')

    def open_model(self):
        self.model = QFileDialog.getOpenFileName(self, '选取模型', os.getcwd(), "Model File(*.pt)")[0]
        if self.model:
            self.det_thread.weights = self.model
        self.statusbar.showMessage('加载模型：' + os.path.basename(self.det_thread.weights))

    def camera(self):
        if self.cam_switch.isChecked():
            self.det_thread.source = '0'
            self.statusbar.showMessage('摄像头已打开')
        else:
            self.det_thread.terminate()
            if hasattr(self.det_thread, 'vid_cap'):
                self.det_thread.vid_cap.release()
            if self.RunProgram.isChecked():
                self.RunProgram.setChecked(False)
            self.statusbar.showMessage('摄像头已关闭')

    def show_statistic(self, statistic_dic):
        try:
            self.listWidget.clear()
            statistic_dic = sorted(statistic_dic.items(), key=lambda x: x[1], reverse=True)
            statistic_dic = [i for i in statistic_dic if i[1] > 0]
            results = [str(i[0]) + '：' + str(i[1]) for i in statistic_dic]
            self.listWidget.addItems(results)

        except Exception as e:
            print(repr(e))

    @staticmethod
    def show_image(img_src, label):
        try:
            ih, iw, _ = img_src.shape
            w = label.geometry().width()
            h = label.geometry().height()
            # 保持纵横比
            # 找出长边
            if iw > ih:
                scal = w / iw
                nw = w
                nh = int(scal * ih)
                img_src_ = cv2.resize(img_src, (nw, nh))
                # 计算差值
                dis = h - nh
                if dis > 0:
                    img_src_ = cv2.copyMakeBorder(img_src_, int(dis / 2), int(dis / 2),
                                                  0, 0, cv2.BORDER_CONSTANT, value=(221, 221, 221))
            else:
                scal = h / ih
                nw = int(scal * iw)
                nh = h
                img_src_ = cv2.resize(img_src, (nw, nh))
                # 计算差值
                dis = w - nw
                if dis > 0:
                    img_src_ = cv2.copyMakeBorder(img_src_, 0, 0, int(dis / 2), int(dis / 2), cv2.BORDER_CONSTANT,
                                                  value=(221, 221, 221))
            frame = cv2.cvtColor(img_src_, cv2.COLOR_BGR2RGB)
            img = QImage(frame.data, frame.shape[1], frame.shape[0], frame.shape[2] * frame.shape[1],
                         QImage.Format_RGB888)
            label.setPixmap(QPixmap.fromImage(img))

        except Exception as e:
            print(repr(e))


if __name__ == "__main__":
    app = QApplication(sys.argv)
    myWin = MainWindow()
    myWin.show()
    sys.exit(app.exec_())

```



